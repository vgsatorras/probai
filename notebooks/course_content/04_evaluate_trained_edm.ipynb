{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Equivariant Diffusion Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "from probai.src.data.mini_qm9 import MiniQM9Dataset\n",
    "from torch_geometric.loader import DataLoader \n",
    "from probai.src.models.ddpm import DDPM\n",
    "from probai.src.models.egnn import EGNNScore\n",
    "from probai.src.training.training_loop import Trainer\n",
    "from probai.src.evaluation.evaluator import Evaluator\n",
    "import torch\n",
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading the validation dataset and creating a DataLoader  \n",
    "dataset_valid = MiniQM9Dataset(file_path=f\"../../raw_data/mini_qm9_valid.pickle\")\n",
    "loader_valid = DataLoader(dataset_valid, batch_size=128, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models from previous checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EGNN\n",
    "with open(\"../../configs/default_config.yml\", 'r') as file:  \n",
    "    config = yaml.safe_load(file)  \n",
    "  \n",
    "egnn_config = config['EGNN']  \n",
    "hidden_nf = egnn_config['hidden_nf']  \n",
    "n_layers = egnn_config['n_layers']  \n",
    "score = EGNNScore(in_node_nf=5 + 1, # 5 for the one hot encoding, 1 for diffusion time\n",
    "        hidden_nf=hidden_nf,\n",
    "        n_layers=n_layers,\n",
    "        out_node_nf=5) # 5 atom types in QM9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DDPM and load checkpoint\n",
    "ddpm_config = config['DDPM']\n",
    "N = config['DDPM']['N'] # Numbero of noise level, default set to 100\n",
    "ddpm = DDPM(noise_schedule_type=\"linear\", model=score, N=N)\n",
    "trainer = Trainer(ddpm)\n",
    "trainer.load_checkpoint(\"../../checkpoints/egnn_checkpoint.pth\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some samples (same as loader_valid.batch_size)\n",
    "evaluator = Evaluator(ddpm, loader_valid=loader_valid)\n",
    "x, h, ptr = evaluator.sample_batch(device=torch.device(\"cuda:0\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate molecule and atom stability\n",
    "\n",
    "<small> For a quickly trained model we expect some decent atom stability (over 50%) and 0% molecule stability. The molecule stability is so low because a single not stalbe atom implies the molecule not being stable. Therefore molecule stability is only achievable after long trainings when atom stability becomes 85% ~ 100%. \n",
    "However, some generated structures may still look qualitatevely well even if they contain a wrong bond. </small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate atom and molecule stabilities. \n",
    "# For a model trained in few epochs we should expect good atom stability and ver low molecule stability.\n",
    "# Large Molecule stability would require longer trainings\n",
    "\n",
    "atom_st, mol_st = evaluator.eval_stability(x, h, ptr)\n",
    "print(f\"Atom stability: {atom_st} \\t Molecule Stability {mol_st}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some sample generated with the trained model\n",
    "evaluator.eval_plot(x, h, ptr, max_num_plots=10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional task\n",
    "If you are curious how the smaples would look in the Gaussian domain without mapping them to the correct distribution you can write the following two lines before they get plotted\n",
    "<code>\n",
    "h=torch.randn(h.shape)  \n",
    "x=torch.randn(x.shape)\n",
    "</code> \n",
    "\n",
    "On the other hand, if you want to use a model previously trained for 200 epochs you can use:  \n",
    "<code>trainer.load_checkpoint(\"../../checkpoints/egnn_checkpoint_instructors.pth\")</code>  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
